<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Affordable VR Eyetracking for Research</title>
    <link rel="stylesheet" href="../../styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <div class="project-container">
        <div class="blur-bg">
            <div class="project-header">
                <h1 class="project-title"><i>EyeTrackVR / Unity</i><br>Affordable VR Eye-Tracking Add-on for Research</h1>
                <div class="project-meta">
                    <span>[Timeline: 2025.01 - 2025.05]</span> | 
                    <span>Role: Independent Developer / Researcher</span>
                </div>
            </div>

            <div class="center">
                <div class="img__wrap">
                        <img src="hardwareSetup.jpg" alt="Project Screenshot" style="width: 100%;">
                </div>
                <p style="text-align: center;">Figure 1: The hardware modification on a non-eye-tracking VR headset.</p>
                <br>
            </div>

            <div class="blur-bg-dense">
                <h2>Overview</h2>
                <br>
                <p>This project presents a <b>cost-effective eye-tracking solution</b> (hardware + software) designed to transform a standard non-eye-tracking VR headset (e.g., Meta Quest 3) into a sophisticated eye-tracking research instrument. The system leverages open-source technology to deliver research-grade eye tracking at a fraction of commercial solutions' cost.</p>
                <div class="img__wrap">
                        <img src="illustration.jpg" alt="Project Screenshot" style="width: 100%;">
                </div>
                <p style="text-align: center;">Figure 2: A simplified illustration of the hardware setup and overall data flow.</p>
            </div>

            <div class="blur-bg-dense">
                <h2>Motivation</h2><br>
                <p>Eye tracking represents a <b>critical component</b> in VR research, enabling precise analysis of user attention patterns, cognitive processes, and interaction behaviors. However, commercial eye-tracking solutions present significant barriers to entry:</p>
                <br>
                <ul>
                    <li><b>High Cost:</b> Professional VR headsets with integrated eye-tracking (e.g., Varjo XR-3, HTC Vive Pro Eye) typically cost between <b>$1,500-$6,500</b>, placing them beyond the reach of many research budgets.</li>
                    <li><b>Limited Accessibility:</b> Many eye-tracking solutions require proprietary software ecosystems or specialized hardware.</li>
                    <li><b>Data Ownership:</b> Commercial platforms may impose restrictions on raw data access or implement "black box" processing algorithms.</li>
                </ul>
                <br>
                <p>This project aims to democratize eye-tracking research by providing an <b>affordable alternative</b> ($200-300 total build cost) while maintaining sufficient accuracy for many research applications.</p>
            </div>

            <div class="blur-bg-dense">
                <h2>Technical Specifications (TODO)</h2>
                <br>
                <ul>
                    <li><b>Sampling Rate:</b> ~50-70Hz (dependent on wireless vs. wired configuration)</li>
                    <li><b>Accuracy:</b> ~Â° visual angle (after calibration)</li>
                    <li><b>Latency:</b> ~ms (dependent on wireless vs. wired configuration)</li>
                    <li><b>Data Output:</b> Real-time gaze vectors and eye openness</li>
                    <li><b>Data Format:</b> OSC protocol for easy integration with research software</li>
                </ul>
            </div>

            <div class="blur-bg-dense">
                <h2>Required Parts</h2>
                <br>
                <p>This project builds upon the open-source <a href="https://docs.eyetrackvr.dev/"><b>EyeTrackVR</b></a> project. Comprehensive assembly guides and technical documentation can be found in their <a href="https://docs.eyetrackvr.dev/">official documentation</a>.</p>
                <br>
                
                <div class="img__wrap">
                    <img src="eyeTrackVR.png" alt="Project Screenshot" style="width: 100%;">
                </div>
            </div>
            <div class="blur-bg-dense">
                <div class="waterfall">
                    <div class="waterfall-item">
                        <div class="img__wrap center">
                            <a href="./quest3.jpg" class="img__link">
                                <img src="./quest3.jpg" alt="quest3" class="img__img">
                                <p class="img__description">Screenshot - Click to enlarge</p>
                            </a>
                            <p>A non-eye-tracking <b>VR headset</b> (e.g., Meta Quest 3, ~$499)</p>
                        </div>
                    </div>
                    <div class="waterfall-item">
                        <div class="img__wrap center">
                            <a href="./IRfilterlessCam.jpg" class="img__link">
                                <img src="./IRfilterlessCam.jpg" alt="socialVRstream" class="img__img">
                                <p class="img__description">Screenshot - Click to enlarge</p>
                            </a>
                            <p>Minimum 2 <b>IR-sensitive mini cameras</b> (recommend purchasing 4 units, as IR filter removal carries risk of damage; ~$10-15 each)</p>
                        </div>
                    </div>
                    <div class="waterfall-item">
                        <div class="img__wrap center">
                            <a href="./xiaoSense.png" class="img__link">
                                <img src="./xiaoSense.png" alt="socialVRstream" class="img__img">
                                <p class="img__description">Screenshot - Click to enlarge</p>
                            </a>
                        </div>
                        <p>2 <b>Microcontroller boards</b> for image processing and data transmission (options include ESP32-CAM, Xiao ESP32S3 Sense; ~$15-25 each)</p>
                    </div>

                    <div class="waterfall-item">
                        <div class="img__wrap center">
                            <a href="./led.png" class="img__link">
                                <img src="./led.png" alt="socialVRstream" class="img__img">
                                <p class="img__description">Screenshot - Click to enlarge</p>
                            </a>
                        </div>
                        <p><b>IR illumination system</b> (recommended to use the official LED set from EyeTrackVR; ~$20)</p>
                    </div>
                </div>
                <br>
                <p>Additional required parts:</p>
                <br>
                <ul>
                    <li>3 <b>USB-C to USB-C cables</b> (2 for cameras, 1 for powering LEDs; ~$10-15 total)</li>
                    <li><a href="https://docs.eyetrackvr.dev/how_to_build/3d_printed_mounts"><b>3D printed mounting hardware</b></a> for cameras, IR emitters, and microcontroller boards (~$5-10 if using a service, or material cost if self-printing)</li>
                    <li>High-quality <b>double-sided adhesive tape</b> (preferably VHB or similar for secure mounting; ~$5-8)</li>
                    <li>1 roll of <b>electrical tape</b> for camera ribbon cable protection (~$3-5)</li>
                    <li><b>Optional:</b> Portable USB power bank for extended wireless operation (~$20-30)</li>
                </ul>
                <br>
                <p><b>Total estimated cost:</b> $200-300 (excluding the VR headset)</p>
                <br>
                <p><b>Note: </b>Most components are available through <b>Amazon</b> with rapid shipping. However, <b>Aliexpress</b> offers significantly lower prices (see <a href="https://docs.eyetrackvr.dev/how_to_build/part_list">EyeTrackVR documentation</a> for specific links). Be aware that Aliexpress shipping typically takes 2-4 weeks, so plan accordingly if pursuing the more economical option.</p>
                
            </div>

            <div class="blur-bg-dense">
                <h2>Assembly Considerations</h2>
                <br>
                <p>
                    When following the EyeTrackVR documentation, pay special attention to these critical points:
                </p>
                <br>
                <p>
                    1. <b>Camera Ribbon Cable Fragility:</b> Minimize camera connection/disconnection cycles. After initial testing, immediately apply protective reinforcement to the ribbon cable as outlined in the <a href="https://docs.eyetrackvr.dev/how_to_build/preparing_cameras">"Protecting a Camera Ribbon Cable"</a> section. These ribbon connections are extremely delicate and prone to failure under repeated stress.
                </p>
                <br>
                <div class="img__wrap center">
                    <a href="./protectcam.png" class="img__link">
                        <img src="./protectcam.png" alt="socialVRstream" class="img__img">
                        <p class="img__description">Screenshot - Click to enlarge</p>
                    </a>
                    <p style="text-align: center;">Figure 3. Apply electrical tape reinforcement to protect the camera ribbon cable.</p>
                <br>
                <p>2. <b>Cable Routing Strategy:</b> Carefully plan your cable routing before permanent installation. The 3D printed camera mounts typically align the ribbon cable outlet with the USB-C port orientation. In my implementation, I intentionally routed the camera ribbon in the opposite direction of the USB-C cable to minimize cable congestion around the headset.
                <br><br>
                If adopting this approach, ensure thorough ribbon cable protection with electrical tape on both sides, and avoid creating sharp bends in the ribbon. Gradual curves are essential for maintaining long-term reliability.</p>
                <br>
                    <div class="img__wrap center">
                        <a href="./cammount.jpg" class="img__link">
                            <img src="./cammount.jpg" alt="socialVRstream" class="img__img">
                            <p class="img__description">Screenshot - Click to enlarge</p>
                        </a>
                    </div>
                    <br>
                <p>3. <b>LED Circuit Orientation:</b> When assembling the EyeTrackVR official LED arrays, note that the circuits for left and right eyes are inverted relative to each other. This design consideration ensures proper IR illumination across the full visual field.</p>
                
                <br>
                <div class="img__wrap center">
                    <a href="./ledcircuit.png" class="img__link">
                        <img src="./ledcircuit.png" alt="socialVRstream" class="img__img">
                        <p class="img__description">Screenshot - Click to enlarge</p>
                    </a>
                </div>
                <br>
            </div>
        </div>
        <div class="blur-bg-dense">
            <h2>Firmware Installation</h2>
            <br>
            <p>The microcontroller boards require appropriate firmware to function correctly:</p>
            <br>
            <ol>
                <li><b>Download the EyeTrackVR firmware</b> from the <a href="https://github.com/EyeTrackVR/OpenIris">official GitHub repository</a></li>
                <li><b>Configure the firmware</b> according to your specific hardware configuration (camera type, board type, etc.)</li>
                <li><b>Flash the firmware</b> to each microcontroller board using the Arduino IDE or PlatformIO</li>
                <li><b>Verify connectivity</b> by accessing the web interface at the IP address assigned to each board</li>
            </ol>
            <br>
            <p><b>Troubleshooting tip:</b> If experiencing connection issues, ensure your computer and the microcontroller boards are on the same WiFi network. Some institutional networks with client isolation may prevent proper communication.</p>
        </div>
        <div class="blur-bg-dense">
            <h2>Testing with EyeTrackVR Receiver</h2>
            <br>
            <p>Before integrating with Unity, it's crucial to verify basic functionality using the EyeTrackVR Receiver application:</p>
            <br>
            <ol>
                <li>TODO: include the python code used for basic data verification</li>
            </ol>
            <br>
            <p>The receiver application provides critical diagnostic information and allows for fine-tuning of tracking parameters before proceeding to Unity integration.</p>
        </div>
        <div class="blur-bg-dense">
            <h2>Unity Integration</h2>
            <br>
            <p>TODO: add the Unity project repository and documentation here</p>
        </div>
        <div class="blur-bg-dense">
            <h2>Performance Comparison</h2>
            <br>
            <p>While this DIY solution cannot match the specifications of high-end commercial systems, it provides sufficient performance for many research applications:</p>
            <br>
            <table style="width:100%; border-collapse: collapse; margin: 20px 0;">
                <tr style="background-color: rgba(100,100,100,0.5);">
                    <th style="padding: 10px; border: 1px solid #ddd; text-align: left;">System</th>
                    <th style="padding: 10px; border: 1px solid #ddd; text-align: left;">Sampling Rate</th>
                    <th style="padding: 10px; border: 1px solid #ddd; text-align: left;">Accuracy</th>
                    <th style="padding: 10px; border: 1px solid #ddd; text-align: left;">Cost</th>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">EyeTrackVR (This Project)</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">~70Hz</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">~Â° visual angle</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">~$200-300</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">Varjo XR-3</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">200Hz</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">< 0.5Â° visual angle</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">~$6,500</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">HTC Vive Pro Eye</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">120Hz</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">~0.5-1.0Â° visual angle</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">~$1,500</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">Meta Quest Pro</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">90Hz</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">~1Â° visual angle</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">~$1,000</td>
                </tr>
            </table>
        </div>
        <div class="blur-bg-dense">
            <h2>Research Applications</h2>
            <br>
            <p>This affordable eye-tracking solution enables various research applications that would otherwise require significantly higher investment:</p>
            <br>
            <ul>
                <li>TODO</li>
            </ul>
        </div>
        <div class="blur-bg-dense">
            <h2>Conclusion</h2>
            <br>
            <p>This project demonstrates that affordable, open-source eye tracking solutions can be successfully implemented for VR research applications. While commercial systems offer higher specifications, this approach dramatically reduces the barrier to entry for eye-tracking research, making it accessible to a wider range of institutions and independent researchers.</p>
            <br>
            <p>The modular nature of this solution also allows for continued improvement and customization to meet specific research needs, representing a valuable contribution to the democratization of advanced VR research methodologies.</p>
        </div>
    </div>
    <script src="../../script.js"></script>
</body>
</html>